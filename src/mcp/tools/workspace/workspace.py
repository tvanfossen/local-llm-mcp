"""Workspace Tool - File Operations with XML Metadata Support

This tool handles all workspace file operations including reading, writing, and managing
files with support for both JSON and XML metadata generated by agents.
"""

import logging
import os
import shutil
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Any, Dict, List

from src.core.utils.utils import create_mcp_response, handle_exception
from src.schemas.files.python_file import (
    PythonFile, PythonClass, PythonMethod, PythonFunction,
    PythonImport, PythonVariable, create_empty_python_file
)
from src.core.files.file_manager import FileManager

logger = logging.getLogger(__name__)


# Initialize file manager for jinja2 template rendering
def _get_file_manager(workspace_root: Path) -> FileManager:
    """Get FileManager instance for template rendering"""
    templates_path = Path("/app/templates")  # Fixed absolute path
    return FileManager(str(workspace_root), str(templates_path))


def _extract_imports_from_body(body: str) -> tuple[list[str], str]:
    """Extract import statements from method body and return (imports, cleaned_body)"""
    import re

    # Find import statements in the body
    import_patterns = [
        r'^(\s*)import\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)\s*$',
        r'^(\s*)from\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)\s+import\s+(.+)\s*$'
    ]

    extracted_imports = []
    cleaned_lines = []

    for line in body.split('\n'):
        is_import = False

        # Check for regular import
        match = re.match(import_patterns[0], line)
        if match:
            module = match.group(2)
            extracted_imports.append(f"import {module}")
            is_import = True

        # Check for from...import
        match = re.match(import_patterns[1], line)
        if match:
            module = match.group(2)
            items = match.group(3)
            extracted_imports.append(f"from {module} import {items}")
            is_import = True

        if not is_import:
            cleaned_lines.append(line)

    cleaned_body = '\n'.join(cleaned_lines).strip()
    return extracted_imports, cleaned_body


def _xml_to_python_file(xml_root: ET.Element, filename: str) -> PythonFile:
    """Convert XML structure to PythonFile schema object"""
    python_file = create_empty_python_file(filename)

    # Track imports extracted from method bodies
    extracted_imports = set()

    try:
        # Extract module docstring from metadata
        metadata_elem = xml_root.find('metadata')
        if metadata_elem is not None:
            desc_elem = metadata_elem.find('description')
            if desc_elem is not None and desc_elem.text:
                python_file.module_docstring = desc_elem.text.strip()

        # Process imports
        imports_elem = xml_root.find('imports')
        if imports_elem is not None:
            for import_elem in imports_elem.findall('import'):
                module = import_elem.get('module', '')
                items = import_elem.get('items', '')
                if module:
                    items_list = [item.strip() for item in items.split(',')] if items else []
                    import_obj = PythonImport(module=module, items=items_list)
                    python_file.add_import(import_obj)

        # Process constants as variables
        constants_elem = xml_root.find('constants')
        if constants_elem is not None:
            for const_elem in constants_elem.findall('constant'):
                name = const_elem.get('name', '')
                const_type = const_elem.get('type', '')
                value = const_elem.get('value', '')
                if name and value:
                    variable = PythonVariable(
                        name=name,
                        type_hint=const_type if const_type else None,
                        value=value
                    )
                    python_file.variables.append(variable)

        # Process functions
        functions_elem = xml_root.find('functions')
        if functions_elem is not None:
            for func_elem in functions_elem.findall('function'):
                name = func_elem.get('name', 'unknown_function')

                # Extract parameters
                parameters = []
                params_elem = func_elem.find('parameters')
                if params_elem is not None:
                    for param_elem in params_elem.findall('parameter'):
                        param_name = param_elem.get('name', '')
                        param_type = param_elem.get('type', '')
                        param_default = param_elem.get('default', '')

                        if param_name:
                            param_dict = {"name": param_name}
                            if param_type:
                                param_dict["type"] = param_type
                            if param_default:
                                param_dict["default"] = param_default
                            parameters.append(param_dict)

                # Extract return type and body
                return_type = None
                returns_elem = func_elem.find('returns')
                if returns_elem is not None:
                    return_type = returns_elem.get('type')

                body = "pass"
                body_elem = func_elem.find('body')
                if body_elem is not None and body_elem.text:
                    raw_body = body_elem.text.strip()
                    # Extract imports from function body
                    body_imports, cleaned_body = _extract_imports_from_body(raw_body)
                    extracted_imports.update(body_imports)
                    body = cleaned_body if cleaned_body else "pass"

                function = PythonFunction(
                    name=name,
                    docstring=None,
                    parameters=parameters,
                    return_type=return_type,
                    body=body
                )
                python_file.add_or_update_function(function)

        # Process classes
        classes_elem = xml_root.find('classes')
        if classes_elem is not None:
            for class_elem in classes_elem.findall('class'):
                class_name = class_elem.get('name', 'UnknownClass')

                # Class docstring
                docstring = None
                docstring_elem = class_elem.find('docstring')
                if docstring_elem is not None and docstring_elem.text:
                    docstring = docstring_elem.text.strip()

                methods = []

                # Process __init__ method
                init_elem = class_elem.find('init_method')
                if init_elem is not None:
                    init_params = []
                    params_elem = init_elem.find('parameters')
                    if params_elem is not None:
                        for param_elem in params_elem.findall('parameter'):
                            param_name = param_elem.get('name', '')
                            param_type = param_elem.get('type', '')
                            param_default = param_elem.get('default', '')

                            if param_name:
                                param_dict = {"name": param_name}
                                if param_type:
                                    param_dict["type"] = param_type
                                if param_default:
                                    param_dict["default"] = param_default
                                init_params.append(param_dict)

                    init_body = "pass"
                    body_elem = init_elem.find('body')
                    if body_elem is not None and body_elem.text:
                        raw_body = body_elem.text.strip()
                        # Extract imports from method body
                        body_imports, cleaned_body = _extract_imports_from_body(raw_body)
                        extracted_imports.update(body_imports)
                        init_body = cleaned_body if cleaned_body else "pass"

                    init_method = PythonMethod(
                        name="__init__",
                        docstring=None,
                        parameters=init_params,
                        return_type=None,
                        body=init_body
                    )
                    methods.append(init_method)

                # Process other methods
                methods_elem = class_elem.find('methods')
                if methods_elem is not None:
                    for method_elem in methods_elem.findall('method'):
                        method_name = method_elem.get('name', 'unknown_method')

                        # Extract parameters
                        method_params = []
                        params_elem = method_elem.find('parameters')
                        if params_elem is not None:
                            for param_elem in params_elem.findall('parameter'):
                                param_name = param_elem.get('name', '')
                                param_type = param_elem.get('type', '')
                                param_default = param_elem.get('default', '')

                                if param_name:
                                    param_dict = {"name": param_name}
                                    if param_type:
                                        param_dict["type"] = param_type
                                    if param_default:
                                        param_dict["default"] = param_default
                                    method_params.append(param_dict)

                        # Extract return type and body
                        method_return_type = None
                        returns_elem = method_elem.find('returns')
                        if returns_elem is not None:
                            method_return_type = returns_elem.get('type')

                        method_body = "pass"
                        body_elem = method_elem.find('body')
                        if body_elem is not None and body_elem.text:
                            raw_body = body_elem.text.strip()
                            # Extract imports from method body
                            body_imports, cleaned_body = _extract_imports_from_body(raw_body)
                            extracted_imports.update(body_imports)
                            method_body = cleaned_body if cleaned_body else "pass"

                        method = PythonMethod(
                            name=method_name,
                            docstring=None,
                            parameters=method_params,
                            return_type=method_return_type,
                            body=method_body
                        )
                        methods.append(method)

                python_class = PythonClass(
                    name=class_name,
                    docstring=docstring,
                    base_classes=[],
                    methods=methods
                )
                python_file.add_or_update_class(python_class)

        # Add all extracted imports from method/function bodies to module level
        for import_stmt in extracted_imports:
            logger.info(f"ðŸ”„ Extracting import from method body: {import_stmt}")
            if import_stmt.startswith('import '):
                module = import_stmt[7:].strip()
                import_obj = PythonImport(module=module, items=[])
                python_file.add_import(import_obj)
            elif import_stmt.startswith('from '):
                # Parse "from module import items"
                parts = import_stmt.split(' import ')
                if len(parts) == 2:
                    module = parts[0][5:].strip()  # Remove "from "
                    items = [item.strip() for item in parts[1].split(',')]
                    import_obj = PythonImport(module=module, items=items)
                    python_file.add_import(import_obj)

        return python_file

    except Exception as e:
        logger.error(f"Error converting XML to PythonFile: {e}")
        raise


async def workspace_tool(arguments: Dict[str, Any]) -> Dict[str, Any]:
    """Workspace operations tool

    Args:
        arguments: Tool arguments containing action and parameters

    Returns:
        MCP response dictionary
    """
    try:
        action = arguments.get("action")
        if not action:
            return create_mcp_response(False, "Missing 'action' parameter")

        # Get the workspace root (default to /workspace for Docker)
        workspace_root = Path(os.environ.get("WORKSPACE_ROOT", "/workspace"))

        if action == "read":
            return await _read_file(arguments, workspace_root)
        elif action == "write":
            return await _write_file(arguments, workspace_root)
        elif action == "delete":
            return await _delete_file(arguments, workspace_root)
        elif action == "list":
            return await _list_directory(arguments, workspace_root)
        elif action == "search":
            return await _search_files(arguments, workspace_root)
        elif action == "create_dir":
            return await _create_directory(arguments, workspace_root)
        elif action == "tree":
            return await _show_tree(arguments, workspace_root)
        elif action == "write_artifact":
            return await _write_artifact(arguments, workspace_root)
        elif action == "write_structured":
            return await _write_structured_file(arguments, workspace_root)
        elif action == "generate_from_metadata":
            return await _generate_from_metadata(arguments, workspace_root)
        else:
            return create_mcp_response(False, f"Unknown workspace action: {action}")

    except Exception as e:
        return handle_exception(e, "workspace_tool")


async def _read_file(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Read file content"""
    try:
        file_path = arguments.get("path")
        if not file_path:
            return create_mcp_response(False, "Missing 'path' parameter for read action")

        full_path = workspace_root / file_path

        if not full_path.exists():
            return create_mcp_response(False, f"File does not exist: {file_path}")

        if not full_path.is_file():
            return create_mcp_response(False, f"Path is not a file: {file_path}")

        # Check if it's a binary file
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            return create_mcp_response(False, f"Cannot read binary file: {file_path}")

        return create_mcp_response(True, f"Read {len(content)} characters from {file_path}", {
            "path": file_path,
            "content": content,
            "size": len(content)
        })

    except Exception as e:
        return handle_exception(e, "_read_file")


async def _write_file(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Write file content with support for agent metadata"""
    try:
        file_path = arguments.get("path")
        content = arguments.get("content", "")

        if not file_path:
            return create_mcp_response(False, "Missing 'path' parameter for write action")

        full_path = workspace_root / file_path

        # Create parent directories if they don't exist
        full_path.parent.mkdir(parents=True, exist_ok=True)

        # Write the file
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)

        # Check if there's metadata for this file and process it
        await _process_file_metadata(file_path, workspace_root)

        return create_mcp_response(True, f"Successfully wrote {len(content)} characters to {file_path}", {
            "path": file_path,
            "size": len(content),
            "created": not full_path.exists()
        })

    except Exception as e:
        return handle_exception(e, "_write_file")


async def _process_file_metadata(file_path: str, workspace_root: Path) -> None:
    """Process agent metadata files (both JSON and XML) for the given file

    This function looks for corresponding .meta files and processes them
    to enhance the generated code with component tracking.
    """
    try:
        meta_dir = workspace_root / ".meta"

        # Check for JSON metadata first (backward compatibility)
        json_meta_file = meta_dir / f"{file_path}.json"
        xml_meta_file = meta_dir / f"{file_path}.xml"

        if xml_meta_file.exists():
            logger.info(f"Found XML metadata for {file_path}, processing...")
            await _process_xml_metadata(file_path, xml_meta_file, workspace_root)
        elif json_meta_file.exists():
            logger.info(f"Found JSON metadata for {file_path}, processing...")
            await _process_json_metadata(file_path, json_meta_file, workspace_root)
        else:
            logger.debug(f"No metadata found for {file_path}")

    except Exception as e:
        logger.error(f"Error processing metadata for {file_path}: {e}")


async def _process_xml_metadata(file_path: str, xml_meta_file: Path, workspace_root: Path) -> None:
    """Process XML metadata file to enhance generated code"""
    try:
        import xml.etree.ElementTree as ET

        # Parse XML metadata
        tree = ET.parse(xml_meta_file)
        root = tree.getroot()

        # Extract component information from XML
        components = []

        # Find all components (classes, functions, etc.)
        for class_elem in root.findall('.//class'):
            components.append({
                'type': 'class',
                'id': class_elem.get('id'),
                'name': class_elem.get('name'),
                'line_start': class_elem.get('line_start'),
                'line_end': class_elem.get('line_end')
            })

        for func_elem in root.findall('.//function'):
            components.append({
                'type': 'function',
                'id': func_elem.get('id'),
                'name': func_elem.get('name'),
                'line_start': func_elem.get('line_start'),
                'line_end': func_elem.get('line_end')
            })

        # Add component tracking comments to the file if components were found
        if components:
            await _add_component_tracking(file_path, components, workspace_root)

        logger.info(f"Processed XML metadata for {file_path}: {len(components)} components")

    except Exception as e:
        logger.error(f"Error processing XML metadata {xml_meta_file}: {e}")


async def _process_json_metadata(file_path: str, json_meta_file: Path, workspace_root: Path) -> None:
    """Process JSON metadata file (backward compatibility)"""
    try:
        import json

        with open(json_meta_file, 'r') as f:
            metadata = json.load(f)

        logger.info(f"Processed JSON metadata for {file_path}: {metadata.get('description', 'No description')}")

    except Exception as e:
        logger.error(f"Error processing JSON metadata {json_meta_file}: {e}")


async def _add_component_tracking(file_path: str, components: List[Dict[str, Any]], workspace_root: Path) -> None:
    """Add component tracking comments to the generated file"""
    try:
        full_path = workspace_root / file_path

        if not full_path.exists():
            return

        with open(full_path, 'r') as f:
            content = f.read()

        # Add component tracking header
        tracking_header = "# Component tracking enabled by agent metadata\n"
        tracking_header += f"# Components: {', '.join([c['name'] for c in components])}\n\n"

        enhanced_content = tracking_header + content

        with open(full_path, 'w') as f:
            f.write(enhanced_content)

        logger.info(f"Added component tracking to {file_path}")

    except Exception as e:
        logger.error(f"Error adding component tracking to {file_path}: {e}")


async def _delete_file(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Delete file or directory"""
    try:
        file_path = arguments.get("path")
        if not file_path:
            return create_mcp_response(False, "Missing 'path' parameter for delete action")

        full_path = workspace_root / file_path

        if not full_path.exists():
            return create_mcp_response(False, f"Path does not exist: {file_path}")

        if full_path.is_file():
            full_path.unlink()
            return create_mcp_response(True, f"Successfully deleted file: {file_path}")
        elif full_path.is_dir():
            shutil.rmtree(full_path)
            return create_mcp_response(True, f"Successfully deleted directory: {file_path}")
        else:
            return create_mcp_response(False, f"Unknown path type: {file_path}")

    except Exception as e:
        return handle_exception(e, "_delete_file")


async def _list_directory(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """List directory contents"""
    try:
        dir_path = arguments.get("path", ".")
        include_hidden = arguments.get("include_hidden", False)
        recursive = arguments.get("recursive", False)

        full_path = workspace_root / dir_path

        if not full_path.exists():
            return create_mcp_response(False, f"Directory does not exist: {dir_path}")

        if not full_path.is_dir():
            return create_mcp_response(False, f"Path is not a directory: {dir_path}")

        files = []
        if recursive:
            for item in full_path.rglob("*"):
                if not include_hidden and item.name.startswith('.'):
                    continue
                relative_path = item.relative_to(workspace_root)
                files.append({
                    "path": str(relative_path),
                    "type": "file" if item.is_file() else "directory",
                    "size": item.stat().st_size if item.is_file() else None
                })
        else:
            for item in full_path.iterdir():
                if not include_hidden and item.name.startswith('.'):
                    continue
                relative_path = item.relative_to(workspace_root)
                files.append({
                    "path": str(relative_path),
                    "type": "file" if item.is_file() else "directory",
                    "size": item.stat().st_size if item.is_file() else None
                })

        return create_mcp_response(True, f"Listed {len(files)} items in {dir_path}", {
            "path": dir_path,
            "files": files,
            "count": len(files)
        })

    except Exception as e:
        return handle_exception(e, "_list_directory")


async def _search_files(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Search for files matching pattern"""
    try:
        pattern = arguments.get("pattern", "*")
        file_pattern = arguments.get("file_pattern", "*.py")
        search_path = arguments.get("path", ".")

        full_path = workspace_root / search_path

        if not full_path.exists():
            return create_mcp_response(False, f"Search path does not exist: {search_path}")

        matches = []
        for item in full_path.rglob(file_pattern):
            if item.is_file():
                relative_path = item.relative_to(workspace_root)
                matches.append({
                    "path": str(relative_path),
                    "size": item.stat().st_size
                })

        return create_mcp_response(True, f"Found {len(matches)} files matching pattern", {
            "pattern": file_pattern,
            "matches": matches,
            "count": len(matches)
        })

    except Exception as e:
        return handle_exception(e, "_search_files")


async def _create_directory(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Create directory"""
    try:
        dir_path = arguments.get("path")
        if not dir_path:
            return create_mcp_response(False, "Missing 'path' parameter for create_dir action")

        full_path = workspace_root / dir_path
        full_path.mkdir(parents=True, exist_ok=True)

        return create_mcp_response(True, f"Successfully created directory: {dir_path}", {
            "path": dir_path
        })

    except Exception as e:
        return handle_exception(e, "_create_directory")


async def _show_tree(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Show directory tree structure"""
    try:
        root_path = arguments.get("path", ".")
        max_depth = arguments.get("max_depth", 3)
        include_hidden = arguments.get("include_hidden", False)

        full_path = workspace_root / root_path

        if not full_path.exists():
            return create_mcp_response(False, f"Path does not exist: {root_path}")

        tree_structure = _build_tree_structure(full_path, workspace_root, max_depth, include_hidden)

        return create_mcp_response(True, f"Directory tree for {root_path}", {
            "path": root_path,
            "tree": tree_structure
        })

    except Exception as e:
        return handle_exception(e, "_show_tree")


def _build_tree_structure(path: Path, workspace_root: Path, max_depth: int, include_hidden: bool, current_depth: int = 0) -> List[Dict[str, Any]]:
    """Build tree structure recursively"""
    if current_depth >= max_depth:
        return []

    items = []
    try:
        for item in sorted(path.iterdir()):
            if not include_hidden and item.name.startswith('.'):
                continue

            relative_path = item.relative_to(workspace_root)
            item_dict = {
                "name": item.name,
                "path": str(relative_path),
                "type": "file" if item.is_file() else "directory"
            }

            if item.is_file():
                item_dict["size"] = item.stat().st_size
            elif item.is_dir():
                item_dict["children"] = _build_tree_structure(
                    item, workspace_root, max_depth, include_hidden, current_depth + 1
                )

            items.append(item_dict)

    except PermissionError:
        # Skip directories we can't read
        pass

    return items


async def _write_artifact(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Write artifact file with special handling"""
    try:
        # This is essentially the same as write but with different semantics
        # Could be used for generated artifacts, templates, etc.
        return await _write_file(arguments, workspace_root)

    except Exception as e:
        return handle_exception(e, "_write_artifact")


async def _write_structured_file(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Write structured file with XML metadata support"""
    try:
        file_path = arguments.get("path")
        structured_content = arguments.get("structured_content")

        if not file_path:
            return create_mcp_response(False, "Missing 'path' parameter for write_structured action")

        if not structured_content:
            return create_mcp_response(False, "Missing 'structured_content' parameter for write_structured action")

        # Import the XML processing modules
        from src.schemas.xml_serializer import PythonComponentXMLSerializer
        from src.schemas.python_components import PythonFile
        from src.core.validation.xml_validator import PythonCodeXMLValidator

        # Parse the structured XML content
        try:
            if isinstance(structured_content, str):
                # If it's a string, wrap it in a root element if needed
                if not structured_content.strip().startswith('<'):
                    return create_mcp_response(False, "structured_content must be valid XML")

                # Parse the XML
                root = ET.fromstring(structured_content)
            else:
                return create_mcp_response(False, "structured_content must be an XML string")

            # Validate the XML structure
            validator = PythonCodeXMLValidator()
            validation_result = validator.validate_xml_string(structured_content)

            if not validation_result.is_valid:
                error_msg = f"Invalid XML structure: {'; '.join(validation_result.errors)}"
                return create_mcp_response(False, error_msg)

            # Generate Python code from the XML structure
            # For now, let's extract basic information and generate simple Python code
            python_code = _generate_python_from_xml(root)

            # Write both the metadata and the generated code
            full_path = workspace_root / file_path

            # Ensure parent directories exist
            full_path.parent.mkdir(parents=True, exist_ok=True)

            # Write the generated Python code
            with open(full_path, "w", encoding="utf-8") as f:
                f.write(python_code)

            # Also save the XML metadata
            meta_dir = workspace_root / ".meta"
            meta_dir.mkdir(exist_ok=True)
            meta_file = meta_dir / f"{file_path}.xml"
            meta_file.parent.mkdir(parents=True, exist_ok=True)

            with open(meta_file, "w", encoding="utf-8") as f:
                f.write(structured_content)

            logger.info(f"âœ… Structured file created: {full_path}")
            logger.info(f"ðŸ“ Metadata saved: {meta_file}")

            return create_mcp_response(
                True,
                f"Successfully created structured file {file_path} with metadata",
                {
                    "file_path": str(full_path),
                    "metadata_path": str(meta_file),
                    "file_size": full_path.stat().st_size
                }
            )

        except ET.ParseError as e:
            return create_mcp_response(False, f"XML parsing error: {e}")
        except Exception as e:
            return create_mcp_response(False, f"Error processing structured content: {e}")

    except Exception as e:
        return handle_exception(e, "_write_structured_file")


def _generate_python_from_xml(xml_root: ET.Element) -> str:
    """Generate Python code from XML structure"""
    try:
        # Extract basic information from XML
        lines = []

        # Add header comment
        lines.append('"""Generated Python file from structured XML metadata"""')
        lines.append('')

        # Process imports
        imports_elem = xml_root.find('imports')
        if imports_elem is not None:
            for import_elem in imports_elem.findall('import'):
                module = import_elem.get('module', '')
                items = import_elem.get('items', '')
                if items:
                    lines.append(f'from {module} import {items}')
                else:
                    lines.append(f'import {module}')
            lines.append('')

        # Process constants
        constants_elem = xml_root.find('constants')
        if constants_elem is not None:
            for const_elem in constants_elem.findall('constant'):
                name = const_elem.get('name', '')
                value = const_elem.get('value', '')
                if name and value:
                    lines.append(f'{name} = {value}')
            lines.append('')

        # Process functions
        functions_elem = xml_root.find('functions')
        if functions_elem is not None:
            for func_elem in functions_elem.findall('function'):
                name = func_elem.get('name', 'unknown_function')

                # Extract parameters
                params = []
                params_elem = func_elem.find('parameters')
                if params_elem is not None:
                    for param_elem in params_elem.findall('parameter'):
                        param_name = param_elem.get('name', '')
                        param_type = param_elem.get('type', '')
                        param_default = param_elem.get('default', '')

                        if param_name:
                            if param_type and param_default:
                                params.append(f'{param_name}: {param_type} = {param_default}')
                            elif param_type:
                                params.append(f'{param_name}: {param_type}')
                            else:
                                params.append(param_name)

                # Extract return type
                return_type = ''
                returns_elem = func_elem.find('returns')
                if returns_elem is not None:
                    return_type = f" -> {returns_elem.get('type', 'None')}"

                # Function signature
                lines.append(f'def {name}({", ".join(params)}){return_type}:')

                # Function body
                body_elem = func_elem.find('body')
                if body_elem is not None and body_elem.text:
                    for line in body_elem.text.strip().split('\n'):
                        lines.append(f'    {line}')
                else:
                    lines.append('    pass')
                lines.append('')

        # Process classes
        classes_elem = xml_root.find('classes')
        if classes_elem is not None:
            for class_elem in classes_elem.findall('class'):
                class_name = class_elem.get('name', 'UnknownClass')

                lines.append(f'class {class_name}:')

                # Class docstring
                docstring_elem = class_elem.find('docstring')
                if docstring_elem is not None and docstring_elem.text:
                    lines.append(f'    """{docstring_elem.text.strip()}"""')
                    lines.append('')

                # Init method
                init_elem = class_elem.find('init_method')
                if init_elem is not None:
                    params = []
                    params_elem = init_elem.find('parameters')
                    if params_elem is not None:
                        for param_elem in params_elem.findall('parameter'):
                            param_name = param_elem.get('name', '')
                            param_type = param_elem.get('type', '')
                            param_default = param_elem.get('default', '')

                            if param_name:
                                if param_type and param_default:
                                    params.append(f'{param_name}: {param_type} = {param_default}')
                                elif param_type:
                                    params.append(f'{param_name}: {param_type}')
                                else:
                                    params.append(param_name)

                    lines.append(f'    def __init__({", ".join(params)}):')

                    body_elem = init_elem.find('body')
                    if body_elem is not None and body_elem.text:
                        for line in body_elem.text.strip().split('\n'):
                            lines.append(f'        {line}')
                    else:
                        lines.append('        pass')
                    lines.append('')

                # Other methods
                methods_elem = class_elem.find('methods')
                if methods_elem is not None:
                    for method_elem in methods_elem.findall('method'):
                        method_name = method_elem.get('name', 'unknown_method')

                        params = []
                        params_elem = method_elem.find('parameters')
                        if params_elem is not None:
                            for param_elem in params_elem.findall('parameter'):
                                param_name = param_elem.get('name', '')
                                param_type = param_elem.get('type', '')
                                param_default = param_elem.get('default', '')

                                if param_name:
                                    if param_type and param_default:
                                        params.append(f'{param_name}: {param_type} = {param_default}')
                                    elif param_type:
                                        params.append(f'{param_name}: {param_type}')
                                    else:
                                        params.append(param_name)

                        return_type = ''
                        returns_elem = method_elem.find('returns')
                        if returns_elem is not None:
                            return_type = f" -> {returns_elem.get('type', 'None')}"

                        lines.append(f'    def {method_name}({", ".join(params)}){return_type}:')

                        body_elem = method_elem.find('body')
                        if body_elem is not None and body_elem.text:
                            for line in body_elem.text.strip().split('\n'):
                                lines.append(f'        {line}')
                        else:
                            lines.append('        pass')
                        lines.append('')

                lines.append('')

        return '\n'.join(lines)

    except Exception as e:
        logger.error(f"Error generating Python code from XML: {e}")
        return f'# Error generating code: {e}\npass\n'


async def _generate_from_metadata(arguments: Dict[str, Any], workspace_root: Path) -> Dict[str, Any]:
    """Generate Python file from existing XML metadata file using jinja2 template"""
    try:
        path = arguments.get("path")
        if not path:
            return create_mcp_response(False, "Missing 'path' parameter")

        # Ensure path is relative
        if path.startswith('/'):
            path = path[1:]

        # Check if metadata file exists
        meta_file = workspace_root / ".meta" / f"{path}.xml"
        if not meta_file.exists():
            return create_mcp_response(False, f"Metadata file not found: {meta_file}")

        logger.info(f"ðŸ“– Reading metadata from: {meta_file}")

        # Read XML metadata
        with open(meta_file, 'r', encoding='utf-8') as f:
            xml_content = f.read()

        # Parse XML to extract structured content
        try:
            # Remove XML declaration and comments for parsing
            clean_xml = xml_content
            if '<?xml' in clean_xml:
                clean_xml = clean_xml.split('?>', 1)[-1]

            # Remove comments
            import re
            clean_xml = re.sub(r'<!--.*?-->', '', clean_xml, flags=re.DOTALL)
            clean_xml = clean_xml.strip()

            # Parse the python_file element
            python_file_root = ET.fromstring(clean_xml)

            if python_file_root.tag != 'python_file':
                return create_mcp_response(False, f"Invalid metadata: root element must be 'python_file', got '{python_file_root.tag}'")

            logger.info(f"ðŸ”„ Converting XML to PythonFile schema for {path}")

            # Convert XML to PythonFile schema object
            python_file_obj = _xml_to_python_file(python_file_root, path)

            logger.info(f"ðŸŽ¨ Rendering Python code using jinja2 template for {path}")

            # Use existing JSONFileManager to render via jinja2
            file_manager = _get_file_manager(workspace_root)

            # Render using the existing, working jinja2 system
            template = file_manager.jinja_env.get_template("python_file.j2")
            # Pass the PythonFile object directly, not converted to dict
            # This preserves methods like to_import_statement()
            template_data = {
                'module_docstring': python_file_obj.module_docstring,
                'imports': python_file_obj.imports,  # Keep PythonImport objects
                'variables': python_file_obj.variables,
                'classes': python_file_obj.classes,
                'functions': python_file_obj.functions,
                'dataclasses': python_file_obj.dataclasses
            }
            python_code = template.render(template_data)

            logger.info(f"âœ… Generated {len(python_code)} characters of Python code")

            # Write the generated Python file
            target_file = workspace_root / path
            target_file.parent.mkdir(parents=True, exist_ok=True)

            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(python_code)

            logger.info(f"âœ… Generated Python file: {target_file}")

            return create_mcp_response(
                True,
                f"âœ… Successfully generated {path} from metadata ({len(python_code)} chars)",
                {
                    "path": path,
                    "metadata_file": str(meta_file),
                    "generated_file": str(target_file),
                    "size": len(python_code)
                }
            )

        except ET.ParseError as e:
            logger.error(f"XML parsing error in metadata file {meta_file}: {e}")
            return create_mcp_response(False, f"Invalid XML in metadata file: {e}")

        except Exception as e:
            logger.error(f"Jinja2 template rendering error for {path}: {e}")
            return create_mcp_response(False, f"Template rendering failed: {e}")

    except Exception as e:
        logger.error(f"Generate from metadata error: {e}")
        return handle_exception(e, "_generate_from_metadata")